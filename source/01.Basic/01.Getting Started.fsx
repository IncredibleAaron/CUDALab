(**
# Getting Started

In this example, I will show you how to code a basic kernel using Alea.cuBase. The example 
creates template by given an unary function (as quotation) and dynamically generate a transform
kernel on that unary function.
*)

(**
Alea.cuBase shipped with a single assembly `Alea.CUDA.dll`. It supports both 32bit and 64bit
process. You can install it via _NuGet Gallery_. In this script, the first step is to reference
`Alea.CUDA.dll`.
*)
#I @"..\..\packages\Alea.cuBase\lib\net40"
#r "Alea.CUDA.dll"

(**
Then open some namespaces:

- `Alea.CUDA` - Core namespace of Alea.cuBase.
- `Alea.CUDA.Utilities` - Some useful utilities.
*)
open Alea.CUDA
open Alea.CUDA.Utilities

(**
Code a kernel quotation generating function. It accepts an unary function expression
as input, and using quotation splicing operator `%` to apply it inside quotation.
*)
let kernel transform =
    <@ fun (n:int) (input:deviceptr<float>) (output:deviceptr<float>) ->
        let start = blockIdx.x * blockDim.x + threadIdx.x
        let stride = gridDim.x * blockDim.x
        let mutable i = start
        while i < n do
            // Use quotation splicing operator "%" to apply
            // the unary transform function.
            output.[i] <- (%transform) input.[i]
            i <- i + stride @>

(**
Code a template generating function. The kernel quotation is generated by above function
and define it as a kernel resource in the template. `cuda` is a workflow which builds
template. The template returns an `Entry` object, which is the _entry point_ of this
template. As we know CUDA programming contains both device side coding and also host
side coding to control the kernel launching and many other issues, the _entry point_
is such host side code to work with this kernel.
*)
let template transform = cuda {
    // Define a kernel by a lambda quotation.
    // The lambda must return a unit.
    let! kernel = transform |> kernel |> Compiler.DefineKernel

    // Define the entry point.
    return Entry(fun program ->
        let worker = program.Worker
        // Apply kernel resource with a program to get kernel runtime.
        let kernel = program.Apply kernel

        // Define a run function.
        let run (input:float[]) =
            let n = input.Length

            // Device memory is IDisposable, easy to use with "use" keyword.
            use input = worker.Malloc(input)
            use output = worker.Malloc(n)

            // For simplicity we use a fixed block size.
            let blockSize = 128
            let numSm = worker.Device.Attributes.MULTIPROCESSOR_COUNT
            // We tend to partition data so that each SM could handle
            // 16 blocks to hide the memory latency.
            // For more detail, please reference "SM Occupancy".
            let gridSize = min (numSm * 16) (divup n blockSize)
            // Now we know the launch shape, could create launching parameter.
            let lp = LaunchParam(gridSize, blockSize)

            // Create two CUDA events to record the kernel execution time.
            use start = worker.CreateEvent()
            use stop = worker.CreateEvent()
            worker.Synchronize()
            start.Record()

            // Now launch the kernel.
            kernel.Launch lp n input.Ptr output.Ptr

            // Record stop event and get the time.
            stop.Record()
            stop.Synchronize()
            let msec = Event.ElapsedMilliseconds(start, stop)

            // Gathering data from device.
            let output = output.Gather()

            // Return output and time.
            output, msec

        // return the run function
        run ) }

(**
A test function, accept a unary function for CPU and a unary function quotation for GPU.
*)
let test cpuTransform gpuTransform tol =
    // Apply unary function quotation to get a template.
    // Then load it into a program.
    // Program is disposble, could use "use" keyword.
    let template = template gpuTransform
    use program = template |> Compiler.load Worker.Default

    // Create random input data.
    let n = 1 <<< 24
    let rng = System.Random(42)
    let input = Array.init n (fun _ -> rng.NextDouble())

    // Calculate on CPU with single threads. To make the time
    // more accurate, we don't count the time for creating the
    // array.
    let cpuResults, cpuTime =
        let output = Array.zeroCreate n
        let watch = System.Diagnostics.Stopwatch.StartNew()
        for i = 0 to n - 1 do output.[i] <- cpuTransform input.[i]
        watch.Stop()
        output, watch.Elapsed.TotalMilliseconds

    // Run the program to get GPU result and time.
    let gpuResults, gpuTime = program.Run input

    // Verify the results.
    let error = ref 0
    (cpuResults, gpuResults) ||> Array.iter2 (fun cpuResult gpuResult ->
        if abs (cpuResult - gpuResult) > tol then error := !error + 1)

    // Print out final results.
    printfn "n=%d:  (CPU %12.6f ms)  (GPU %10.6f ms)  (Error %d)"
            n cpuTime gpuTime !error

(** Print the GPU device name. *)
printfn "GPU: %s" Worker.Default.Device.Name

(** A simple test for function sin. *)
test sin <@ sin @> 1e-12

(** Another test. *)
test (fun x -> (pown (sin x) 2) * (pown (cos x) 2))
     <@ fun x -> (pown (sin x) 2) * (pown (cos x) 2) @>
     1e-12
